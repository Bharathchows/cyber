{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGvlcX3LraQ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset from the local file\n",
        "file_path = \"/path/to/your/mitbih_test.csv\"  # Replace with the actual path to your file\n",
        "df = pd.read_csv(file_path, header=None)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display basic statistics of the dataset\n",
        "print(\"\\nBasic statistics of the dataset:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Display class distribution\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df[187].value_counts())\n",
        "\n",
        "# Visualize class distribution\n",
        "sns.countplot(x=df[187])\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "# Explore correlation between features\n",
        "correlation_matrix = df.corr()\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Task 4: Pre-process the Data to Identify the Best Features\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 1. Random Forest\n",
        "print(\"\\nRandom Forest Classifier:\")\n",
        "# Initialize and train the machine learning model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test, y_rf_pred)\n",
        "report_rf = classification_report(y_test, y_rf_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy_rf}\")\n",
        "print(\"Classification Report:\\n\", report_rf)\n",
        "\n",
        "# 2. Support Vector Machine (SVM)\n",
        "print(\"\\nSupport Vector Machine (SVM):\")\n",
        "# Initialize and train the machine learning model\n",
        "svm_model = SVC(random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_svm = accuracy_score(y_test, y_svm_pred)\n",
        "report_svm = classification_report(y_test, y_svm_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy_svm}\")\n",
        "print(\"Classification Report:\\n\", report_svm)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for visualization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Compare Performance of Random Forest and Support Vector Machine\n",
        "\n",
        "# Compare accuracy\n",
        "print(\"\\nComparison of Model Performances:\")\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
        "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
        "\n",
        "# Compare classification reports\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(report_rf)\n",
        "print(\"\\nSVM Classification Report:\")\n",
        "print(report_svm)\n",
        "\n",
        "# Visualize confusion matrices\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Confusion Matrix for Random Forest\n",
        "plt.subplot(1, 2, 1)\n",
        "cm_rf = confusion_matrix(y_test, y_rf_pred)\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['N', 'S', 'V', 'F', 'Q'],\n",
        "            yticklabels=['N', 'S', 'V', 'F', 'Q'])\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "# Confusion Matrix for Support Vector Machine\n",
        "plt.subplot(1, 2, 2)\n",
        "cm_svm = confusion_matrix(y_test, y_svm_pred)\n",
        "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=['N', 'S', 'V', 'F', 'Q'],\n",
        "            yticklabels=['N', 'S', 'V', 'F', 'Q'])\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TI-Mj7dIrdYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}